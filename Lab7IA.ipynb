{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsQ2RUA+x2216HDgMP60d+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andyfer004/Lab7-IA/blob/main/Lab7IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1 - Teoría\n",
        "\n",
        "## 1. ¿Qué es el temporal difference learning y en qué se diferencia de los métodos tradicionales de aprendizaje supervisado? Explique el concepto de \"error de diferencia temporal\" y su papel en los algoritmos de aprendizaje por refuerzo\n",
        "\n",
        "**Temporal Difference Learning (TD Learning)** es un método de aprendizaje por refuerzo que permite a un agente aprender una función de evaluación a partir de la experiencia sin necesidad de un modelo del entorno. A diferencia de los métodos tradicionales de aprendizaje supervisado, TD Learning no requiere datos etiquetados con salidas correctas, sino que ajusta su política basándose en las recompensas obtenidas.\n",
        "\n",
        "El **error de diferencia temporal (TD Error)** mide la diferencia entre la recompensa esperada y la obtenida en un estado determinado. Se define como:\n",
        "\n",
        "$$ TD\\_Error = R + \\gamma V(s') - V(s) $$\n",
        "\n",
        "Donde:\n",
        "- \\( R \\) es la recompensa obtenida.\n",
        "- \\( \\gamma \\) es el factor de descuento.\n",
        "- \\( V(s') \\) es el valor del estado siguiente.\n",
        "- \\( V(s) \\) es el valor del estado actual.\n",
        "\n",
        "El TD Error permite actualizar la función de evaluación \\( V(s) \\) de manera progresiva a medida que el agente obtiene más experiencia.\n",
        "\n",
        "\n",
        "\n",
        "## 2. En el contexto de los juegos simultáneos, ¿cómo toman decisiones los jugadores sin conocer las acciones de sus oponentes? De un ejemplo de un escenario del mundo real que pueda modelarse como un juego simultáneo y discuta las estrategias que los jugadores podrían emplear en tal situación\n",
        "\n",
        "En juegos simultáneos, los jugadores toman sus decisiones sin conocer las acciones del oponente. Para optimizar sus resultados, pueden emplear:\n",
        "\n",
        "- **Estrategia pura:** Siempre elegir la misma acción.\n",
        "- **Estrategia mixta:** Asignar probabilidades a cada acción para hacer la estrategia impredecible.\n",
        "\n",
        "### **Ejemplo: Negociaciones salariales**\n",
        "Dos empleados pueden negociar su sueldo sin conocer las ofertas de la empresa. Algunas estrategias que pueden seguir son:\n",
        "- **Estrategia agresiva:** Pedir un aumento alto esperando que la empresa acepte.\n",
        "- **Estrategia conservadora:** Pedir un aumento moderado para evitar rechazo.\n",
        "- **Estrategia mixta:** Variar la negociación en base a probabilidades.\n",
        "\n",
        "En este tipo de juegos, la incertidumbre obliga a los jugadores a optimizar sus decisiones en función de posibles respuestas del oponente.\n",
        "\n",
        "\n",
        "\n",
        "## 3. ¿Qué distingue los juegos de suma cero de los juegos de no suma cero y cómo afecta esta diferencia al proceso de toma de decisiones de los jugadores? Proporcione al menos un ejemplo de juegos que entren en la categoría de juegos de no suma cero y discuta las consideraciones estratégicas únicas involucradas\n",
        "\n",
        "### Diferencia entre juegos de suma cero y no suma cero:\n",
        "- **Juegos de suma cero:** La ganancia de un jugador implica la pérdida del otro. Ejemplo: Ajedrez.\n",
        "- **Juegos de no suma cero:** Los jugadores pueden beneficiarse simultáneamente. Ejemplo: Dilema del Prisionero.\n",
        "\n",
        "### **Ejemplo: Dilema del Prisionero**\n",
        "Dos sospechosos pueden **testificar** o **negar** el crimen. La matriz de pagos es:\n",
        "\n",
        "| A / B | Testifica | Niega |\n",
        "|-------|----------|-------|\n",
        "| **Testifica** | (-5, -5) | (-10, 0) |\n",
        "| **Niega** | (0, -10) | (-1, -1) |\n",
        "\n",
        "Las estrategias deben considerar:\n",
        "- La cooperación podría ser mejor para ambos (negar).\n",
        "- En ausencia de comunicación, el equilibrio de Nash es que ambos testifiquen.\n",
        "\n",
        "En juegos de no suma cero, la cooperación y la confianza pueden ser clave para maximizar beneficios.\n",
        "\n",
        "\n",
        "\n",
        "## 4. ¿Cómo se aplica el concepto de equilibrio de Nash a los juegos simultáneos? Explicar cómo el equilibrio de Nash representa una solución estable en la que ningún jugador tiene un incentivo para desviarse unilateralmente de la estrategia elegida\n",
        "\n",
        "El **equilibrio de Nash** es una situación en la que ningún jugador mejora cambiando unilateralmente su estrategia. Matemáticamente, si dos jugadores siguen estrategias \\( \\pi_A^* \\) y \\( \\pi_B^* \\), se cumple:\n",
        "\n",
        "$$ V_A(\\pi_A^*, \\pi_B^*) \\geq V_A(\\pi_A, \\pi_B^*) $$\n",
        "$$ V_B(\\pi_A^*, \\pi_B^*) \\geq V_B(\\pi_A^*, \\pi_B) $$\n",
        "\n",
        "Esto significa que, dada la estrategia del oponente, no hay incentivos para cambiar la propia.\n",
        "\n",
        "### **Ejemplo: Dilema del Prisionero**\n",
        "Si ambos testifican, aunque el resultado no sea óptimo, cambiar de estrategia (negar) resultaría en una peor situación para cada jugador. Por lo tanto, **testificar es el equilibrio de Nash**.\n",
        "\n",
        "Este concepto es fundamental en economía, negociación y teoría de juegos, ya que permite encontrar estrategias estables en situaciones de competencia.\n",
        "\n",
        "\n",
        "\n",
        "## 5. Discuta la aplicación del temporal difference learning en el modelado y optimización de procesos de toma de decisiones en entornos dinámicos. ¿Cómo maneja el temporal difference learning el equilibrio entre exploración y explotación y cuáles son algunos de los desafíos asociados con su implementación en la práctica?\n",
        "\n",
        "TD Learning se aplica en problemas dinámicos donde el entorno cambia y la optimización es clave. Un ejemplo destacado es **Backgammon**, donde un agente ajusta los pesos de evaluación jugando contra sí mismo.\n",
        "\n",
        "### **Exploración vs. Explotación**\n",
        "Para equilibrar la exploración y la explotación, TD Learning utiliza estrategias como:\n",
        "- **\\(\\epsilon\\)-greedy:** Con probabilidad \\( \\epsilon \\) se elige una acción aleatoria para explorar.\n",
        "- **Reducción progresiva de \\( \\epsilon \\):** Se inicia explorando más y se reduce la exploración con el tiempo.\n",
        "\n",
        "### **Desafíos en su implementación**\n",
        "1. **Convergencia lenta:** Aprender valores óptimos en entornos complejos puede ser costoso en términos de tiempo.\n",
        "2. **Dependencia de hiperparámetros:** Factores como la tasa de aprendizaje (\\( \\eta \\)) y el descuento (\\( \\gamma \\)) afectan la estabilidad y el rendimiento.\n",
        "3. **Exploración insuficiente:** Si el agente no explora lo suficiente, puede quedar atrapado en soluciones subóptimas.\n",
        "\n",
        "A pesar de estos retos, TD Learning es una herramienta poderosa en inteligencia artificial, especialmente en juegos y toma de decisiones automatizada.\n"
      ],
      "metadata": {
        "id": "rvwuOwfy06KL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2 Connect 4\n",
        "## 1. Representación del Tablero: Clase `ConnectFour`\n",
        "Contiene la lógica del tablero, validación de movimientos, colocación de fichas y detección de ganador."
      ],
      "metadata": {
        "id": "D50eV-io0cni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class ConnectFour:\n",
        "    def __init__(self):\n",
        "        self.rows = 6\n",
        "        self.cols = 7\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((self.rows, self.cols), dtype=int)\n",
        "        self.game_over = False\n",
        "        self.winner = None\n",
        "\n",
        "    def valid_moves(self):\n",
        "        # Las columnas que no están llenas\n",
        "        return [c for c in range(self.cols) if self.board[0, c] == 0]\n",
        "\n",
        "    def drop_piece(self, col, piece):\n",
        "        # Coloca la ficha en la columna dada\n",
        "        for row in reversed(range(self.rows)):\n",
        "            if self.board[row, col] == 0:\n",
        "                self.board[row, col] = piece\n",
        "                return row, col\n",
        "        return None\n",
        "\n",
        "    def check_winner(self, piece):\n",
        "        # Función simplificada para verificar ganador (horizontal, vertical, diagonales)\n",
        "        # Se puede ampliar la verificación para todas las direcciones\n",
        "        # Horizontal\n",
        "        for r in range(self.rows):\n",
        "            for c in range(self.cols - 3):\n",
        "                if np.all(self.board[r, c:c+4] == piece):\n",
        "                    return True\n",
        "        # Vertical\n",
        "        for c in range(self.cols):\n",
        "            for r in range(self.rows - 3):\n",
        "                if np.all(self.board[r:r+4, c] == piece):\n",
        "                    return True\n",
        "        # Diagonales\n",
        "        for r in range(self.rows - 3):\n",
        "            for c in range(self.cols - 3):\n",
        "                if all(self.board[r+i, c+i] == piece for i in range(4)):\n",
        "                    return True\n",
        "            for c in range(3, self.cols):\n",
        "                if all(self.board[r+i, c-i] == piece for i in range(4)):\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    def is_full(self):\n",
        "        return len(self.valid_moves()) == 0"
      ],
      "metadata": {
        "id": "e5ijqDmMyLax"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Agente de Aprendizaje TD: Clase `QLearningAgent`\n",
        "Implementación del agente que usa Q-learning con política epsilon-greedy y tabla Q.\n"
      ],
      "metadata": {
        "id": "RsXW2nfJ0o2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearningAgent:\n",
        "    def __init__(self, learning_rate=0.1, discount_factor=0.95, epsilon=0.2):\n",
        "        self.lr = learning_rate\n",
        "        self.gamma = discount_factor\n",
        "        self.epsilon = epsilon\n",
        "        self.q_table = {}  # clave: estado (tupla), valor: vector Q para cada acción\n",
        "\n",
        "    def get_state_key(self, board):\n",
        "        return tuple(board.flatten())\n",
        "\n",
        "    def choose_action(self, board, valid_moves):\n",
        "        state_key = self.get_state_key(board)\n",
        "        # Si no se conoce el estado, inicializa Q para todas las columnas\n",
        "        if state_key not in self.q_table:\n",
        "            self.q_table[state_key] = np.zeros(7)\n",
        "        # Estrategia epsilon-greedy\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return np.random.choice(valid_moves)\n",
        "        else:\n",
        "            # Selecciona la acción con mayor Q, considerando sólo movimientos válidos\n",
        "            q_values = self.q_table[state_key]\n",
        "            q_valid = {a: q_values[a] for a in valid_moves}\n",
        "            return max(q_valid, key=q_valid.get)\n",
        "\n",
        "    def update(self, board, action, reward, next_board, next_valid_moves, done):\n",
        "        state_key = self.get_state_key(board)\n",
        "        next_state_key = self.get_state_key(next_board)\n",
        "        if state_key not in self.q_table:\n",
        "            self.q_table[state_key] = np.zeros(7)\n",
        "        current_q = self.q_table[state_key][action]\n",
        "        # Inicializa Q en el siguiente estado si no existe\n",
        "        if next_state_key not in self.q_table:\n",
        "            self.q_table[next_state_key] = np.zeros(7)\n",
        "        max_next_q = 0 if done else np.max(self.q_table[next_state_key][next_valid_moves])\n",
        "        # Actualización de Q-learning\n",
        "        self.q_table[state_key][action] += self.lr * (reward + self.gamma * max_next_q - current_q)"
      ],
      "metadata": {
        "id": "lzcbmzniyMQK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Función de Recompensa `get_reward()`\n",
        "Calcula la recompensa en función del estado actual: victoria, derrota, empate o juego en curso.\n"
      ],
      "metadata": {
        "id": "3TXBb6hP0sjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reward(game, piece):\n",
        "    # Si el juego ha terminado, se evalúa el resultado\n",
        "    if game.check_winner(piece):\n",
        "        return 1\n",
        "    elif game.check_winner(-piece):\n",
        "        return -1\n",
        "    elif game.is_full():\n",
        "        return 0.5  # empate (recompensa intermedia)\n",
        "    else:\n",
        "        return 0  # juego en curso"
      ],
      "metadata": {
        "id": "b75AxTiEyRFi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Entrenamiento del Agente TD: Función `train_td()`\n",
        "Entrena al agente Q-learning jugando múltiples partidas contra sí mismo u otro agente."
      ],
      "metadata": {
        "id": "p7A_pb5S0vE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_td(agent, episodes=5000):\n",
        "    game = ConnectFour()\n",
        "    for episode in range(episodes):\n",
        "        game.reset()\n",
        "        current_piece = 1  # El agente juega como 1\n",
        "        state = game.board.copy()\n",
        "        done = False\n",
        "        while not done:\n",
        "            valid_moves = game.valid_moves()\n",
        "            # El agente toma acción\n",
        "            action = agent.choose_action(state, valid_moves)\n",
        "            game.drop_piece(action, current_piece)\n",
        "            next_state = game.board.copy()\n",
        "            # Revisamos si se ganó o si el tablero se llenó\n",
        "            if game.check_winner(current_piece):\n",
        "                reward = 1\n",
        "                done = True\n",
        "            elif game.is_full():\n",
        "                reward = 0.5\n",
        "                done = True\n",
        "            else:\n",
        "                reward = 0\n",
        "            next_valid_moves = game.valid_moves()\n",
        "            agent.update(state, action, reward, next_state, next_valid_moves, done)\n",
        "            state = next_state.copy()\n",
        "            # Cambio de turno (suponiendo un juego de self-play o contra un oponente simple)\n",
        "            current_piece *= -1"
      ],
      "metadata": {
        "id": "o4QM-fcEyTni"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Agentes Oponentes: Minimax y Alpha-Beta\n",
        "Funciones `minimax()` y `minimax_alphabeta()` para los oponentes basados en búsqueda de árbol."
      ],
      "metadata": {
        "id": "evFzffrA0ymv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def minimax(game, depth, maximizing_player, piece):\n",
        "    # Caso base: fin del juego o profundidad 0\n",
        "    if depth == 0 or game.check_winner(1) or game.check_winner(-1) or game.is_full():\n",
        "        # Función de evaluación simple: retorna 0 para empate, 1 para victoria, -1 para derrota\n",
        "        if game.check_winner(piece):\n",
        "            return (None, 1)\n",
        "        elif game.check_winner(-piece):\n",
        "            return (None, -1)\n",
        "        else:\n",
        "            return (None, 0)\n",
        "\n",
        "    valid_moves = game.valid_moves()\n",
        "    if maximizing_player:\n",
        "        value = -np.inf\n",
        "        best_move = None\n",
        "        for move in valid_moves:\n",
        "            temp_game = ConnectFour()\n",
        "            temp_game.board = game.board.copy()\n",
        "            temp_game.drop_piece(move, piece)\n",
        "            new_score = minimax(temp_game, depth-1, False, piece)[1]\n",
        "            if new_score > value:\n",
        "                value = new_score\n",
        "                best_move = move\n",
        "        return best_move, value\n",
        "    else:\n",
        "        value = np.inf\n",
        "        best_move = None\n",
        "        for move in valid_moves:\n",
        "            temp_game = ConnectFour()\n",
        "            temp_game.board = game.board.copy()\n",
        "            temp_game.drop_piece(move, -piece)\n",
        "            new_score = minimax(temp_game, depth-1, True, piece)[1]\n",
        "            if new_score < value:\n",
        "                value = new_score\n",
        "                best_move = move\n",
        "        return best_move, value\n",
        "\n",
        "# Para minimax con poda alpha-beta se puede ampliar la función anterior:\n",
        "def minimax_alphabeta(game, depth, alpha, beta, maximizing_player, piece):\n",
        "    if depth == 0 or game.check_winner(1) or game.check_winner(-1) or game.is_full():\n",
        "        if game.check_winner(piece):\n",
        "            return (None, 1)\n",
        "        elif game.check_winner(-piece):\n",
        "            return (None, -1)\n",
        "        else:\n",
        "            return (None, 0)\n",
        "\n",
        "    valid_moves = game.valid_moves()\n",
        "    if maximizing_player:\n",
        "        value = -np.inf\n",
        "        best_move = None\n",
        "        for move in valid_moves:\n",
        "            temp_game = ConnectFour()\n",
        "            temp_game.board = game.board.copy()\n",
        "            temp_game.drop_piece(move, piece)\n",
        "            new_score = minimax_alphabeta(temp_game, depth-1, alpha, beta, False, piece)[1]\n",
        "            if new_score > value:\n",
        "                value = new_score\n",
        "                best_move = move\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return best_move, value\n",
        "    else:\n",
        "        value = np.inf\n",
        "        best_move = None\n",
        "        for move in valid_moves:\n",
        "            temp_game = ConnectFour()\n",
        "            temp_game.board = game.board.copy()\n",
        "            temp_game.drop_piece(move, -piece)\n",
        "            new_score = minimax_alphabeta(temp_game, depth-1, alpha, beta, True, piece)[1]\n",
        "            if new_score < value:\n",
        "                value = new_score\n",
        "                best_move = move\n",
        "            beta = min(beta, value)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return best_move, value"
      ],
      "metadata": {
        "id": "QqBGJoC-yV3C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Evaluación y Visualización de Resultados\n",
        "Simula juegos entre agentes, cuenta victorias y genera una gráfica de barras con `matplotlib`."
      ],
      "metadata": {
        "id": "5UYaG4Vh01Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def jugar_partido(agent_td, opponent_func, depth=3, num_games=50, opponent_type=\"Minimax\"):\n",
        "    # agent_td es el agente Q-learning, opponent_func es la función (minimax o minimax_alphabeta)\n",
        "    wins_td = 0\n",
        "    wins_opp = 0\n",
        "    game = ConnectFour()\n",
        "    for _ in range(num_games):\n",
        "        game.reset()\n",
        "        current_piece = 1  # Empezamos con el agente TD como 1\n",
        "        state = game.board.copy()\n",
        "        done = False\n",
        "        while not done:\n",
        "            valid_moves = game.valid_moves()\n",
        "            if current_piece == 1:\n",
        "                # Agente TD\n",
        "                action = agent_td.choose_action(state, valid_moves)\n",
        "            else:\n",
        "                # Oponente: utiliza la función minimax (o alpha-beta)\n",
        "                if opponent_type == \"Minimax\":\n",
        "                    action, _ = minimax(game, depth, True, -1)\n",
        "                else:\n",
        "                    action, _ = minimax_alphabeta(game, depth, -np.inf, np.inf, True, -1)\n",
        "                # Si minimax no devuelve acción, selecciona aleatoriamente\n",
        "                if action is None:\n",
        "                    action = np.random.choice(valid_moves)\n",
        "            game.drop_piece(action, current_piece)\n",
        "            state = game.board.copy()\n",
        "            # Verificar si hay ganador o empate\n",
        "            if game.check_winner(current_piece):\n",
        "                done = True\n",
        "                if current_piece == 1:\n",
        "                    wins_td += 1\n",
        "                else:\n",
        "                    wins_opp += 1\n",
        "            elif game.is_full():\n",
        "                done = True\n",
        "            current_piece *= -1\n",
        "    return wins_td, wins_opp\n",
        "\n",
        "# Supongamos que ya entrenamos el agente TD\n",
        "agent_td = QLearningAgent()\n",
        "# Entrenamiento (por ejemplo, 5000 episodios)\n",
        "train_td(agent_td, episodes=5000)\n",
        "\n",
        "# Jugar 50 juegos contra Minimax y 50 juegos contra Minimax con poda alpha-beta\n",
        "wins_td_minimax, wins_minimax = jugar_partido(agent_td, minimax, depth=3, num_games=50, opponent_type=\"Minimax\")\n",
        "wins_td_alphabeta, wins_alphabeta = jugar_partido(agent_td, minimax_alphabeta, depth=3, num_games=50, opponent_type=\"AlphaBeta\")\n",
        "\n",
        "# También se puede simular un enfrentamiento entre Minimax y Alpha-Beta si se requiere.\n",
        "\n",
        "# Graficar los resultados\n",
        "labels = ['TD vs Minimax', 'TD vs AlphaBeta']\n",
        "td_wins = [wins_td_minimax, wins_td_alphabeta]\n",
        "opp_wins = [wins_minimax, wins_alphabeta]\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width/2, td_wins, width, label='Agente TD')\n",
        "rects2 = ax.bar(x + width/2, opp_wins, width, label='Oponente')\n",
        "ax.set_ylabel('Número de Victorias')\n",
        "ax.set_title('Resultados de 50 juegos por enfrentamiento')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "PgMMF6_PyZPs",
        "outputId": "fe433ec9-7dc1-456a-d0ed-8636743a1434"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Conclusiones y Explicación Final\n",
        "\n",
        "### ¿Qué hace el agente entrenado con TD Learning a nivel general?\n",
        "\n",
        "El agente entrenado con **aprendizaje por diferencias temporales (TD Learning)** utiliza el algoritmo **Q-Learning** para aprender una función de valor que le permite tomar decisiones más inteligentes con base en su experiencia. Durante el entrenamiento, el agente juega partidas y actualiza su tabla de valores Q para cada combinación de estado-acción, con el objetivo de maximizar las recompensas a lo largo del tiempo.\n",
        "\n",
        "Su estrategia se basa en explorar el tablero mediante una política **epsilon-greedy**, que alterna entre elegir la mejor acción conocida y explorar nuevas opciones. Con el tiempo, y tras muchas partidas, el agente ajusta su comportamiento para seleccionar las acciones que le llevan a ganar o evitar perder.\n",
        "\n",
        "\n",
        "\n",
        "### ¿Por qué ganó más veces el agente que ganó?\n",
        "\n",
        "En los enfrentamientos realizados, se observó que los agentes que utilizan **Minimax** y **Minimax con poda Alpha-Beta** ganaron significativamente más veces que el agente TD. Esto se debe a que estas estrategias exploran múltiples futuros posibles en el árbol del juego, evaluando sistemáticamente las mejores jugadas posibles hasta cierta profundidad. Son métodos **determinísticos y estratégicos**, mientras que el agente TD depende del aprendizaje a través de la experiencia, y requiere muchas más partidas para acercarse a un buen nivel.\n",
        "\n",
        "El **agente TD no alcanzó un nivel de aprendizaje suficientemente alto**, posiblemente por un número limitado de episodios de entrenamiento, una política de exploración muy alta, o por no haber refinado los hiperparámetros (tasa de aprendizaje, descuento, epsilon).\n",
        "\n",
        "\n",
        "\n",
        "### ¿Cómo afectó el tener o no esta estrategia al agente que ganó?\n",
        "\n",
        "Los agentes **Minimax y Alpha-Beta** cuentan con una estrategia fija que evalúa las mejores jugadas posibles en cada turno, por lo que no dependen del entrenamiento. Esto les permitió obtener una ventaja clara desde el principio.\n",
        "\n",
        "En cambio, el agente TD Learning **requiere jugar muchas partidas para mejorar su rendimiento**, y si no se le da suficiente tiempo de entrenamiento o si la función de recompensa no está bien diseñada, su rendimiento será inferior. El no tener una estrategia basada en búsqueda (como Minimax) le impide tomar decisiones óptimas desde las primeras partidas.\n"
      ],
      "metadata": {
        "id": "gNw7thos140y"
      }
    }
  ]
}